# -*- coding: utf-8 -*-
"""5G_Resource_Allocation.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1QGunoJXjfa485yZ5Eq9sqZD4D7kpLyCV

Importing required libraries
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

"""### Data Collection and Preprocessing

Reading Dataset
"""

df = pd.read_csv('/content/Quality of Service 5G.csv')
df.head()

df.shape

df.info()

"""Handling Missing Values

"""

df.isnull().sum()

"""Note : There are no missing values in the dataset

Removing unwanted features (User_ID and Timestamp)
"""

new_df = df.drop(['Timestamp', 'User_ID'], axis=1)
new_df.head()

"""Handling Categorical Columns (Label Encoding)"""

new_df.Application_Type.nunique()

new_df.Application_Type.value_counts()

from sklearn.preprocessing import LabelEncoder
le = LabelEncoder()
new_df['Application_Type'] = le.fit_transform(new_df['Application_Type'])
new_df.head()

data = pd.DataFrame({'index':[0,1,2,3,4,5,6,7,8,9,10],
        'Application_Type':['Video_Call','Web_Browsing','Streaming','Emergency_Service','Background_Download','Video_Streaming','VoIP_Call','Online_Gaming','IoT_Temperature','Voice_Call','File_Download']})
data['ID'] = le.fit_transform(data['Application_Type'].values)
data = data.drop_duplicates('Application_Type').set_index('index')
print(data)

"""Regex Clenaing"""

# Removing units of Signal_Strength, Latenecy, Resource Allocation

new_df['Signal_Strength'] = new_df['Signal_Strength'].str.extract('(\d+)').astype(int)
new_df['Latency'] = new_df['Latency'].str.extract('(\d+)').astype(int)
new_df['Resource_Allocation'] = new_df['Resource_Allocation'].str.extract('(\d+)').astype(int)

new_df.head()

"""Converting units from Mbps to Kbps"""

new_df[['Size','Unit']] = new_df.Allocated_Bandwidth.str.split(' ', expand=True)
new_df['Size'] = new_df.Size.astype(float)
new_df.Unit.replace({'Mbps': 1024, 'Kbps': 1}, inplace=True)
new_df['Allocated_Bandwidth(Kbps)'] = new_df.Size * new_df.Unit

new_df[['Size1','Unit1']] = new_df.Required_Bandwidth.str.split(' ', expand=True)
new_df['Size1'] = new_df.Size1.astype(float)
new_df.Unit1.replace({'Mbps': 1024, 'Kbps': 1}, inplace=True)
new_df['Required_Bandwidth(Kbps)'] = new_df.Size1 * new_df.Unit1

new_df.head()

new_df.drop(columns='Size',inplace=True)
new_df.drop(columns='Unit',inplace=True)

new_df.drop(columns='Size1',inplace=True)
new_df.drop(columns='Unit1',inplace=True)

new_df.drop(columns='Allocated_Bandwidth',inplace=True)
new_df.drop(columns='Required_Bandwidth',inplace=True)

new_df.head()

"""Descriptive Analytics"""

new_df.describe()

"""Handling Outliers"""

sns.boxplot(new_df.Application_Type)

"""Note : There are no outliers in Application_Type feature."""

sns.boxplot(new_df.Signal_Strength)

"""Note : There are no outliers in Signal_Strength feature."""

sns.boxplot(new_df.Latency)

# Replacing outliers in Latencey with median of Latency

q1 = new_df.Latency.quantile(0.25) #Q1
q3 = new_df.Latency.quantile(0.75) #Q3
print(q1)
print(q3)

IQR = q3 - q1
print(IQR)

upper_limit = q3+(1.5)*(IQR)
lower_limit = q1-(1.5)*(IQR)
print(upper_limit)
print(lower_limit)

new_df.Latency.median()

new_df['Latency'] = np.where(new_df['Latency'] > upper_limit, new_df.Latency.median(), new_df['Latency'])
sns.boxplot(new_df.Latency)

"""Note : Outliers in Latency column are replaced using Median of Latency"""

# Replacing outliers in Allocated_Bandwidth(Kbps) with median

q1_AB = new_df['Allocated_Bandwidth(Kbps)'].quantile(0.25) #Q1
q3_AB = new_df['Allocated_Bandwidth(Kbps)'].quantile(0.75) #Q3
print(q1_AB)
print(q3_AB)

IQR_AB = q3_AB - q1_AB
print(IQR_AB)

upper_limit_AB = q3_AB+(1.5)*(IQR_AB)
lower_limit_AB = q1_AB-(1.5)*(IQR_AB)
print(upper_limit_AB)
print(lower_limit_AB)

new_df['Allocated_Bandwidth(Kbps)'].median()

new_df['Allocated_Bandwidth(Kbps)'] = np.where(new_df['Allocated_Bandwidth(Kbps)'] > upper_limit_AB, new_df['Allocated_Bandwidth(Kbps)'].median(), new_df['Allocated_Bandwidth(Kbps)'])
sns.boxplot(new_df['Allocated_Bandwidth(Kbps)'])

"""Note : Outliers in Allocated_Bandwidth(Kbps) column are replaced using Median"""

sns.boxplot(new_df['Required_Bandwidth(Kbps)'])

# Replacing outliers in Allocated_Bandwidth(Kbps) with median

q1_RB = new_df['Required_Bandwidth(Kbps)'].quantile(0.25) #Q1
q3_RB = new_df['Required_Bandwidth(Kbps)'].quantile(0.75) #Q3
print(q1_RB)
print(q3_RB)

IQR_RB = q3_RB - q1_RB
print(IQR_RB)

new_df['Required_Bandwidth(Kbps)'].median()

upper_limit_RB = q3_RB+(1.5)*(IQR_RB)
lower_limit_RB = q1_RB-(1.5)*(IQR_RB)
print(upper_limit_RB)
print(lower_limit_RB)

new_df['Required_Bandwidth(Kbps)'] = np.where(new_df['Required_Bandwidth(Kbps)'] > upper_limit_RB, new_df['Required_Bandwidth(Kbps)'].median(), new_df['Required_Bandwidth(Kbps)'])
sns.boxplot(new_df['Required_Bandwidth(Kbps)'])

"""Note : Outliers in Required_Bandwidth(Kbps) column are replaced using Median

### Data Visualisation
"""

import plotly.express as px

"""Visualising Latency by Application_Type"""

plt.figure(figsize=(12, 6))
sns.barplot(x='Application_Type', y='Latency', data=new_df)
plt.title('Latency by Application Type')
plt.xticks(rotation=45)
plt.show()

"""Visualize Signal_Strength by Application_Type"""

plt.figure(figsize=(12, 6))
sns.barplot(x='Application_Type', y='Signal_Strength', data=new_df)
plt.title('Signal Strength by Application Type')
plt.xticks(rotation=45)
plt.show()

"""Visualising distribution of Application Types"""

plt.figure(figsize=(10, 6))
sns.countplot(data=df, x='Application_Type')
plt.title('Distribution of Application Types')
plt.xticks(rotation=45)
plt.xlabel('Application Type')
plt.ylabel('Count')
plt.show()

"""Most Commonly Used Application Types

"""

application_counts = df['Application_Type'].value_counts()
application_counts

plt.figure(figsize=(10, 6))
sns.barplot(x=application_counts.index, y=application_counts.values, palette="viridis")
plt.title('Most Commonly Used Application Types')
plt.xlabel('Application Type')
plt.ylabel('Count')
plt.xticks(rotation=90)
plt.show()

"""Distribution of Resource Allocation"""

plt.figure(figsize=(10, 6))
sns.histplot(data=new_df, x='Resource_Allocation', bins=10 ,kde=True)
plt.title('Distribution of Resource Allocation')
plt.xlabel('Resource Allocation (%)')
plt.ylabel('Count')
plt.show()

"""Distribution of Signal Strength"""

plt.figure(figsize=(10, 12))
sns.histplot(data=new_df, x='Signal_Strength', bins=20, kde=True)
plt.title('Distribution of Signal Strength')
plt.xlabel('Signal Strength')
plt.ylabel('Frequency')
plt.show()

"""Correlation between Signal Strength and Allocated Bandwidth"""

plt.figure(figsize=(8, 6))
sns.scatterplot(data=new_df, x='Signal_Strength', y='Allocated_Bandwidth(Kbps)',)
plt.title('Correlation Between Signal Strength and Allocated Bandwidth')
plt.xlabel('Signal Strength')
plt.ylabel('Allocated Bandwidth')
plt.grid(True)
plt.show()

"""Relationship between Allocated Bandwidth and Required Bandwidth"""

plt.figure(figsize=(8, 6))
sns.scatterplot(data=new_df, x='Required_Bandwidth(Kbps)', y='Allocated_Bandwidth(Kbps)')
plt.title('Relationship Between Allocated Bandwidth and Required Bandwidth')
plt.xlabel('Required Bandwidth')
plt.ylabel('Allocated Bandwidth')
plt.grid(True)
plt.show()

"""Top 8 application using high latency"""

app_name = df.Application_Type.value_counts().index
lat_val = df.Latency.value_counts().values
plt.pie(lat_val[:7],labels = app_name[:7],autopct='%1.f%%');

new_df.corr()

plt.figure(figsize=(10,8))
sns.heatmap(new_df.corr(),annot =True)

"""### X and Y splits"""

Y=new_df['Resource_Allocation']
Y

X=new_df.drop(columns=['Resource_Allocation'],axis=1)
X

"""### Train and Test splits"""

from sklearn.model_selection import train_test_split
X_train,X_test,Y_train,Y_test = train_test_split(X,Y,test_size=0.3,random_state=42)

X_train.shape

X_test.shape

"""### Model Building

1. Linear regression
"""

from sklearn.linear_model import LinearRegression
model = LinearRegression()
model.fit(X_train,Y_train)
Y_pred =model.predict(X_test)
Y_pred

res = pd.DataFrame({'Actual Resource Allocated':Y_test,'Predictd Resource Allocation':Y_pred})
res

"""2. Logistic regression"""

from sklearn.linear_model import LogisticRegression
model2 = LogisticRegression()
model2.fit(X_train,Y_train)
Y_pred_2 =model2.predict(X_test)
Y_pred_2

res_2 = pd.DataFrame({'Actual Resource Allocated':Y_test,'Predictd Resource Allocation':Y_pred_2})
res_2

"""3. Decision-Tree regressor"""

from sklearn.tree import DecisionTreeRegressor

model3 = DecisionTreeRegressor()
model3.fit(X_train,Y_train)
Y_pred_3 =model3.predict(X_test)
Y_pred_3

res_3 = pd.DataFrame({'Actual Resource Allocated':Y_test,'Predictd Resource Allocation':Y_pred_3})
res_3

"""4. Random Forest Regressor"""

from sklearn.ensemble import RandomForestRegressor
model4 = RandomForestRegressor(n_estimators=200)
model4.fit(X_train,Y_train)
Y_pred_4 =model4.predict(X_test)
Y_pred_4

res_4 = pd.DataFrame({'Actual Resource Allocated':Y_test,'Predictd Resource Allocation':Y_pred_4})
res_4

"""5. Polynomial regression"""

from sklearn.preprocessing import PolynomialFeatures
from sklearn.linear_model import LinearRegression
from sklearn.pipeline import make_pipeline
degree = 2
model5 = make_pipeline(PolynomialFeatures(degree), LinearRegression())
model5.fit(X_train,Y_train)
Y_pred_5 =model5.predict(X_test)
Y_pred_5

res_5 = pd.DataFrame({'Actual Resource Allocated':Y_test,'Predictd Resource Allocation':Y_pred_5})
res_5

"""6. Ridge and Lasso regression"""

from sklearn.linear_model import Ridge
from sklearn.linear_model import Lasso

r = Ridge()
l = Lasso()

r.fit(X_train,Y_train)

Y_pred_6 =r.predict(X_test)
Y_pred_6

res_6 = pd.DataFrame({'Actual Resource Allocated':Y_test,'Predictd Resource Allocation':Y_pred_6})
res_6

l.fit(X_train,Y_train)
Y_pred_7 =l.predict(X_test)
Y_pred_7

res_7 = pd.DataFrame({'Actual Resource Allocated':Y_test,'Predictd Resource Allocation':Y_pred_7})
res_7

"""### Performance Testing"""

from sklearn import metrics
from sklearn.metrics import accuracy_score, confusion_matrix ,classification_report

"""1. Linear Regression"""

Y_pred_train =model.predict(X_train)
print("Training accuracy:", metrics.r2_score(Y_train, Y_pred_train))
print("Testing accuracy:", metrics.r2_score(Y_test, Y_pred))

"""2. Logistic regression"""

Y_pred_2_train =model2.predict(X_train)
print("Training accuracy:", accuracy_score(Y_train, Y_pred_2_train))
print("Testing accuracy:", accuracy_score(Y_test, Y_pred_2))

# Classification report for Logistic Regression

import warnings
warnings.filterwarnings("ignore", category=UserWarning)
print(classification_report(Y_test, Y_pred_2))

"""3. Decision-Tree Regressor"""

Y_pred_3_train =model3.predict(X_train)
print("Training accuracy:", accuracy_score(Y_train, Y_pred_3_train))
print("Testing accuracy:", accuracy_score(Y_test, Y_pred_3))

# Classification report for Decision-Tree Regressor

warnings.filterwarnings("ignore", category=UserWarning)
print(classification_report(Y_test, Y_pred_3))

"""4. Random Forest Regressor"""

from sklearn.metrics import mean_squared_error, r2_score

# Training Accuracy
Y_pred_4_train = model4.predict(X_train)
train_mse = mean_squared_error(Y_train, Y_pred_4_train)
train_r2 = r2_score(Y_train, Y_pred_4_train)

# Testing Accuracy
test_mse = mean_squared_error(Y_test, Y_pred_4)
test_r2 = r2_score(Y_test, Y_pred_4)

print("Training Mean Squared Error:", train_mse)
print("Training R-squared:", train_r2)
print("Testing Mean Squared Error:", test_mse)
print("Testing R-squared:", test_r2)

"""5. Polynomial regression"""

# Training Accuracy
Y_pred_5_train = model5.predict(X_train)
train_mse_1 = mean_squared_error(Y_train, Y_pred_5_train)
train_r2_1 = r2_score(Y_train, Y_pred_5_train)

# Testing Accuracy
test_mse_1 = mean_squared_error(Y_test, Y_pred_5)
test_r2_1 = r2_score(Y_test, Y_pred_5)

print("Training Mean Squared Error:", train_mse_1)
print("Training R-squared:", train_r2_1)
print("Testing Mean Squared Error:", test_mse_1)
print("Testing R-squared:", test_r2_1)

"""6. Lasso and Ridge Regression"""

print(metrics.r2_score(Y_test,Y_pred_6))
print(metrics.r2_score(Y_test,Y_pred_7))

"""Note: Random Forest Regressor is found to be the best model with "Training r2-score : 99.18%" and "Testing r2-score : 87.46%"

### Model Deployment
"""

import pickle
pickle.dump(model4,open('5G_Quality.pkl','wb'))

"""### Testing with random values

"""

model4.predict([[6,85,30,2560,5240]])

model4.predict([[10,75,20,15050,18952]])

model4.predict([[2,75,20,20,58]])

"""### Tuning Model"""

from sklearn.model_selection import GridSearchCV

param_grid = {
    'n_estimators': [100, 200, 300],  # Number of trees in the forest
    'max_depth': [None, 10, 20, 30],  # Maximum depth of the trees
    'min_samples_split': [2, 5, 10],  # Minimum number of samples required to split an internal node
    'min_samples_leaf': [1, 2, 4],  # Minimum number of samples required to be a leaf node
}

grid_search = GridSearchCV(estimator=model4, param_grid=param_grid, cv=5, scoring='neg_mean_squared_error', n_jobs=-1)

grid_search.fit(X_train, Y_train)

print("Best hyperparameters:", grid_search.best_params_)
print("Best score:", -grid_search.best_score_)

from sklearn.ensemble import RandomForestRegressor
params = {
    'max_depth': 20,
    'min_samples_leaf': 1,
    'min_samples_split': 2,
    'n_estimators': 200
}
model4_tuned = RandomForestRegressor(**params)
model4_tuned.fit(X_train,Y_train)
Y_pred_4_tuned =model4_tuned.predict(X_test)
Y_pred_4_tuned

res_4_tuned = pd.DataFrame({'Actual Resource Allocated':Y_test,'Predictd Resource Allocation':Y_pred_4_tuned})
res_4_tuned

from sklearn.metrics import mean_squared_error, r2_score

# Training Accuracy
Y_pred_4_train_tuned = model4.predict(X_train)
train_mse_tuned = mean_squared_error(Y_train, Y_pred_4_train_tuned)
train_r2_tuned = r2_score(Y_train, Y_pred_4_train_tuned)

# Testing Accuracy
test_mse_tuned = mean_squared_error(Y_test, Y_pred_4_tuned)
test_r2_tuned = r2_score(Y_test, Y_pred_4_tuned)

print("Training Mean Squared Error:", train_mse_tuned)
print("Training R-squared:", train_r2_tuned)
print("Testing Mean Squared Error:", test_mse_tuned)
print("Testing R-squared:", test_r2_tuned)